[{"authors":null,"date":1673050767,"fuzzywordcount":2200,"image":"images/allpost/vertical-aksdbz.png","kind":"page","lastmod":1673050767,"objectID":"0ff6aaa5b11630bc3d348f334950d48c","permalink":"https://anhcodes.dev/blog/deploy-debezium-aks/","publishdate":"2023-01-07T00:19:27Z","readingtime":11,"relpermalink":"/blog/deploy-debezium-aks/","section":"blog","summary":"This tutorial follows Debezium official documentation Deploying Debezium on Kubernetes, but modified for Azure Kubernetes Service and Azure Container Registry.\nTable of Content 1. Prerequisites\n2. Deploy strimzi operator\n3. Create secrets and roles\n4. Deploy Kafka cluster\n5. Deploy mysql database in Kubernetes\n6. Deploy Kafka Connect Cluster\nStep 1: Create secret for container registry Step 2: Build and push Kafka connecti image with debezium connector plugins to container registry Step 3: Deploy kafka connect cluster Step 4: Validate kafka connect cluster 7.","tags":["kafka","kubernetes","debezium","strimzi","change-data-capture","docker"],"title":"Deploy Debezium and Kafka on AKS using Strimzi Operator","type":"blog","url":"/blog/deploy-debezium-aks/","wordcount":2182,"writtendate":null},{"authors":null,"date":1672617659,"fuzzywordcount":200,"image":"images/allpost/pyspark-synapse-vertical.jpg","kind":"page","lastmod":1672617659,"objectID":"17f9f4e4bdb98bd6c152285aed3db861","permalink":"https://anhcodes.dev/blog/how-to-read-synapse-table-spark/","publishdate":"2023-01-02T00:00:59Z","readingtime":1,"relpermalink":"/blog/how-to-read-synapse-table-spark/","section":"blog","summary":"Thanks to Azure Synapse Dedicated SQL Pool Connector for Apache Spark, you can directly read Synapse Dedicated SQL Pool tables into Spark dataframe with Python and Scala using Synapse Spark Pool. These solutions work when the Spark Pool and the Dedicated SQL Pool are in the same workspaces.\nTo create Synapse Spark Pool in Azure Synapse, you can follow this documentation. .\nOption 1: Use Scala In Synapse Workspace, you can right-click the table in Dedicated SQL Pool database, and pick Load to Dataframe","tags":["azure-synapse-analytics","how-to","pyspark"],"title":"How to read Azure Synapse Tables to Spark Dataframe","type":"blog","url":"/blog/how-to-read-synapse-table-spark/","wordcount":153,"writtendate":null},{"authors":null,"date":1672598955,"fuzzywordcount":200,"image":"images/single-blog/fireworks.gif","kind":"page","lastmod":1672598955,"objectID":"7b9d75ebe54110fe547d1effe61eabed","permalink":"https://anhcodes.dev/blog/goodbye-2022/","publishdate":"2023-01-01T18:49:15Z","readingtime":1,"relpermalink":"/blog/goodbye-2022/","section":"blog","summary":"2022 was kind to me with exciting changes and opportunities. Take a look at what I accomplished last year:\nüèÜ Received Excellence Award at Walmart\n‚ú® Completed the Neural Networks and Deep Learning Course by DeepLearning.ai\nüéâ Started my dream job at Microsoft\nüì¶ Moved to Seattle, WA - the Evergreen State\nü§ì Got the Azure Data Engineering Associate Certification\nüíª Participated in Microsoft Global Hackathon\nüèîÔ∏è Went on 12 gorgeous hikes in Washington state\u0026hellip; and counting","tags":["career","life"],"title":"Goodbye 2022! May 2023 Be Fabulous","type":"blog","url":"/blog/goodbye-2022/","wordcount":115,"writtendate":null},{"authors":null,"date":1672140620,"fuzzywordcount":900,"image":"images/allpost/git-reset.png","kind":"page","lastmod":1672140620,"objectID":"1a54754f6b88a3dc0eb67248079128bd","permalink":"https://anhcodes.dev/blog/recover-lost-files-git-reset-hard/","publishdate":"2022-12-27T11:30:20Z","readingtime":5,"relpermalink":"/blog/recover-lost-files-git-reset-hard/","section":"blog","summary":"While working on a recent project, I accidentally committed some files. Instead of using git reset --soft \u0026lt;prev-commit-id\u0026gt; to unstage them, I used git reset --hard HEAD and all of my new changes gone with the wind. After panicking for a few minutes, I determined to learn how git reset works and how I can revert the damages.\n1. What is git reset (hard vs soft) git reset --hard resets the current branch tip, and also deletes any changes in the working directory and staging area (although files under git stash will not be affected).","tags":["tip","git"],"title":"How to recover lost files after a git reset --hard","type":"blog","url":"/blog/recover-lost-files-git-reset-hard/","wordcount":881,"writtendate":null},{"authors":null,"date":1671062400,"fuzzywordcount":1200,"image":"/images/allpost/query-performance.jpeg","kind":"page","lastmod":1671062400,"objectID":"dcbf64a8d85ce3cd6d7a8b3d1bf0362b","permalink":"https://anhcodes.dev/blog/query-performance/","publishdate":"2022-12-15T00:00:00Z","readingtime":6,"relpermalink":"/blog/query-performance/","section":"blog","summary":"1. Best practices when Creating Tables When creating table in Dedicated SQL Pool, choose the correct Distribution Column and Index for best query performance. Follow Best Practices in creating tables in Azure Synapse Analytics\nRemember to create and Update Stats on your new tables Table statistics for dedicated SQL pool in Azure Synapse Analytics\n2. Identify slow-running QID and analyze compilation To best determine what is causing any given query\u0026rsquo;s slow performance, you will need to identify an example long-running query:","tags":["azure-synapse-analytics","data-lakehouse","tip"],"title":"Query Performance Tuning in Dedicated SQL Pool (Azure Synapse Analytics)","type":"blog","url":"/blog/query-performance/","wordcount":1145,"writtendate":null},{"authors":null,"date":1668554670,"fuzzywordcount":500,"image":"images/allpost/sql-pool-vertical.jpeg","kind":"page","lastmod":1668554670,"objectID":"8bfe313fba251eda375e099706ef95af","permalink":"https://anhcodes.dev/blog/create-table-azure-synapse-analytics/","publishdate":"2022-11-15T23:24:30Z","readingtime":2,"relpermalink":"/blog/create-table-azure-synapse-analytics/","section":"blog","summary":"As Dedicated SQL pool uses a scaled-out node based architecture, when creating tables in Dedicated SQL Pool, remember to specify the distribution (sharding strategy) and index for your tables.\nDedicated SQL Pool Architecture Choosing Distribution: The data is sharded into distributions to optimize the performance of the system. You can choose which sharding pattern to use to distribute the data when you define the table. These sharding patterns are supported:","tags":["azure-synapse-analytics"],"title":"Best Practices in creating tables in Azure Synapse Analytics","type":"blog","url":"/blog/create-table-azure-synapse-analytics/","wordcount":416,"writtendate":null},{"authors":null,"date":1668470400,"fuzzywordcount":1000,"image":"images/allpost/azure-synapse.jpeg","kind":"page","lastmod":1668470400,"objectID":"287520668b5ffc83fb305913c56e7c32","permalink":"https://anhcodes.dev/blog/synapse/","publishdate":"2022-11-15T00:00:00Z","readingtime":5,"relpermalink":"/blog/synapse/","section":"blog","summary":"Table of Contents What is Azure Synapse Analytics? What is Dedicated SQL Pool? What is Serverless SQL Pool? Dedicated vs Serverless SQL Pool Comparison Azure Synapse Analytics, AWS Redshift, Google Big Query Comparison What is Azure Synapse Analytics? Azure Synapse Analytics is an integrated data platform that brings together SQL technologies used in enterprise data warehousing such as Dedicated SQL Pool and Serverless SQL Pool, Synapse Spark Pool used for big data, Data Explorer for log and time series analytics, Synapse Pipelines for data integration and ETL/ELT, and deep integration with other Azure services such as Power BI, CosmosDB, and AzureML.","tags":["azure-synapse-analytics","big-query","redshift","data-lakehouse"],"title":"Azure Synapse Analytics - Data Lakehouse on Azure","type":"blog","url":"/blog/synapse/","wordcount":987,"writtendate":null}]