<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark on anhcodes</title>
    <link>https://anhcodes.dev/tags/spark/</link>
    <description>Recent content in spark on anhcodes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 27 May 2023 21:48:00 +0000</lastBuildDate><atom:link href="https://anhcodes.dev/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Spark working internals, and why should you care?</title>
      <link>https://anhcodes.dev/blog/tune-spark/</link>
      <pubDate>Sat, 27 May 2023 21:48:00 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/tune-spark/</guid>
      <description>Most Big Data developers and Data Engineers start learning Spark by learning how to write SparkSQLcodes, how to ingest data and perform transformations on DataFrame (I know I did). I also wrote a post about SparkSQL Programming. However, we quickly learn that thereâ€™s more knowlege required to go from processing a few GBs of data to dealing with TBs and PBs of data, which is a challenge for big enterprises. Learning to write correct Spark codes is only a small part of the battle, you will need to understand the Spark Architecture and Spark working internals to correct tune Spark to handle true big data, and itâ€™s the focus of this post.</description>
    </item>
    
    <item>
      <title>Spark SQL Programming Primer</title>
      <link>https://anhcodes.dev/blog/spark-sql-programming/</link>
      <pubDate>Tue, 23 May 2023 17:09:34 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/spark-sql-programming/</guid>
      <description>TL,DR - SparkSQL is a huge component of Spark Programming. This post introduces programming in SparkSQL through Spark DataFrame API. It&amp;rsquo;s important to be aware of Spark SQL built-in functions to be a more efficient Spark programmer
What is SparkSQL DataFrame API in SparkSQL Read and write data with Spark DataFrame Work with columns in DF Work with Rows in DF Data Operations in Spark DataFrame SparkSQL Built-in Functions 1. Aggregation functions 2.</description>
    </item>
    
    <item>
      <title>Debug long running Spark job</title>
      <link>https://anhcodes.dev/blog/debug-spark/</link>
      <pubDate>Mon, 22 May 2023 17:09:41 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/debug-spark/</guid>
      <description>You Spark job is running for a long time, what to do? Generally, long-running Spark jobs can be due to various factors. We like to call them the 5S - Spill, Skew, Shuffle, Storage, and Serialization. So, how do we identify the main culprit?
ðŸ”Ž Look for Skew: Are some of the tasks taking longer than others? Do you have a join operation?
ðŸ”Ž Look for Spill: Any out-of-memory errors? Do the executors have enough memory to finish their tasks?</description>
    </item>
    
  </channel>
</rss>
