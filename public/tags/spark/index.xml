<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark on anhcodes</title>
    <link>https://anhcodes.dev/tags/spark/</link>
    <description>Recent content in spark on anhcodes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Apr 2023 23:20:57 +0000</lastBuildDate><atom:link href="https://anhcodes.dev/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How to Scale and Tune Spark Effectively</title>
      <link>https://anhcodes.dev/blog/scale-spark/</link>
      <pubDate>Tue, 11 Apr 2023 23:20:57 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/scale-spark/</guid>
      <description>Spark is a distributed big data processing engine that uses the resilient distributed dataset (RDD) data structure with data abstractions such as DataFrames and Datasets. It provides API in different programming languages such as Scala, Python, and Java. One of the key benefits of Spark is that it decouples compute and storage, meaning it can be used to read from different data sources on-prem and in the cloud. Spark has four main APIs: Spark SQL, Spark MLlib, Spark Structured Streaming, and GraphX.</description>
    </item>
    
  </channel>
</rss>
