<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark on anhcodes</title>
    <link>https://anhcodes.dev/tags/spark/</link>
    <description>Recent content in spark on anhcodes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 May 2023 17:09:34 +0000</lastBuildDate><atom:link href="https://anhcodes.dev/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Spark SQL Programming Primer</title>
      <link>https://anhcodes.dev/blog/spark-sql-programming/</link>
      <pubDate>Tue, 23 May 2023 17:09:34 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/spark-sql-programming/</guid>
      <description>TL,DR - SparkSQL is a huge component of Spark Programming. This post introduces programming in SparkSQL through Spark DataFrame API. It&amp;rsquo;s important to be aware of Spark SQL built-in functions to be a more efficient Spark programmer
What is SparkSQL DataFrame API in SparkSQL Read and write data with Spark DataFrame Work with columns in DF Work with Rows in DF Data Operations in Spark DataFrame SparkSQL Built-in Functions 1. Aggregation functions 2.</description>
    </item>
    
    <item>
      <title>Debug long running Spark job</title>
      <link>https://anhcodes.dev/blog/debug-spark/</link>
      <pubDate>Mon, 22 May 2023 17:09:41 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/debug-spark/</guid>
      <description>You Spark job is running for a long time, what to do? Generally, long-running Spark jobs can be due to various factors. We like to call them the 5S - Spill, Skew, Shuffle, Storage, and Serialization. So, how do we identify the main culprit?
ðŸ”Ž Look for Skew: Are some of the tasks taking longer than others? Do you have a join operation?
ðŸ”Ž Look for Spill: Any out-of-memory errors? Do the executors have enough memory to finish their tasks?</description>
    </item>
    
    <item>
      <title>How to Scale and Tune Spark Effectively</title>
      <link>https://anhcodes.dev/blog/tune-spark/</link>
      <pubDate>Tue, 11 Apr 2023 23:20:57 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/tune-spark/</guid>
      <description>Spark is a distributed big data processing engine that uses the resilient distributed dataset (RDD) data structure with data abstractions such as DataFrames and Datasets. It provides API in different programming languages such as Scala, Python, and Java. One of the key benefits of Spark is that it decouples compute and storage, meaning it can be used to read from different data sources on-prem and in the cloud. Spark has four main APIs: Spark SQL, Spark MLlib, Spark Structured Streaming, and GraphX.</description>
    </item>
    
  </channel>
</rss>
