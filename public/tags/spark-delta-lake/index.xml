<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark delta-lake on anhcodes</title>
    <link>https://anhcodes.dev/tags/spark-delta-lake/</link>
    <description>Recent content in spark delta-lake on anhcodes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 07 Aug 2023 11:23:00 +0000</lastBuildDate><atom:link href="https://anhcodes.dev/tags/spark-delta-lake/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Deep Dive Into Delta Lake</title>
      <link>https://anhcodes.dev/blog/deep-dive-delta-lake/</link>
      <pubDate>Mon, 07 Aug 2023 11:23:00 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/deep-dive-delta-lake/</guid>
      <description>Delta Lake is an open source storage layer that brings reliability to data lakes. Delta Lake provides ACID transactions, scalable metadata handling, and unifies streaming and batch data processing. Delta Lake runs on top of your existing data lake and is fully compatible with Apache Spark APIs. Delta Lake uses versioned Parquet files to store your data in your cloud storage. Apart from the versions, Delta Lake also stores a transaction log to keep track of all the commits made to the table or blob store directory to provide ACID transactions.</description>
    </item>
    
  </channel>
</rss>
