<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data-lakehouse on anhcodes</title>
    <link>https://anhcodes.dev/categories/data-lakehouse/</link>
    <description>Recent content in data-lakehouse on anhcodes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 30 Dec 2023 16:02:25 +0000</lastBuildDate><atom:link href="https://anhcodes.dev/categories/data-lakehouse/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Data Objects in Databricks</title>
      <link>https://anhcodes.dev/blog/data-objects/</link>
      <pubDate>Sat, 30 Dec 2023 16:02:25 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/data-objects/</guid>
      <description>Metastore and Catalog In Databricks, metadata of data Objects (tables, views, etc.) is registered in Metastore.
Previously, Databricks uses Hive metastore by default to register schemas, tables, and views. However, it&amp;rsquo;s highly recommended to upgrade to Unity Catalog to access centralized access control, auditing, lineage, and data discovery capabilities.
Catalog is a group of databases. If you want to use Unity Catalog, create and specify Catalog is required (Set up and manage Unity Catalog).</description>
    </item>
    
    <item>
      <title>Deep Dive Into Delta Lake</title>
      <link>https://anhcodes.dev/blog/deep-dive-delta-lake/</link>
      <pubDate>Mon, 07 Aug 2023 11:23:00 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/deep-dive-delta-lake/</guid>
      <description>Delta Lake is an open source storage layer that brings reliability to data lakes. Delta Lake provides ACID transactions, scalable metadata handling, and unifies streaming and batch data processing. Delta Lake runs on top of your existing data lake and is fully compatible with Apache Spark APIs. Delta Lake uses versioned Parquet files to store your data in your cloud storage. Apart from the versions, Delta Lake also stores a transaction log to keep track of all the commits made to the table or blob store directory to provide ACID transactions.</description>
    </item>
    
    <item>
      <title>Navigate Databricks FileSystem</title>
      <link>https://anhcodes.dev/blog/dbfs/</link>
      <pubDate>Tue, 11 Apr 2023 22:13:33 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/dbfs/</guid>
      <description> View Fullscreen View on Github </description>
    </item>
    
    <item>
      <title>Query Performance Tuning in Dedicated SQL Pool (Azure Synapse Analytics)</title>
      <link>https://anhcodes.dev/blog/query-performance/</link>
      <pubDate>Thu, 15 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/query-performance/</guid>
      <description>1. Best practices when Creating Tables When creating table in Dedicated SQL Pool, choose the correct Distribution Column and Index for best query performance. Follow Best Practices in creating tables in Azure Synapse Analytics
Remember to create and Update Stats on your new tables Table statistics for dedicated SQL pool in Azure Synapse Analytics
2. Identify slow-running QID and analyze compilation To best determine what is causing any given query&amp;rsquo;s slow performance, you will need to identify an example long-running query:</description>
    </item>
    
  </channel>
</rss>
