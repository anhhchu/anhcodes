<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data, Coding &amp; More on anhcodes</title>
    <link>https://anhcodes.dev/blog/</link>
    <description>Recent content in Data, Coding &amp; More on anhcodes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 May 2023 18:06:47 +0000</lastBuildDate><atom:link href="https://anhcodes.dev/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Create your own AI avatar with DreamBooth and Stable Diffusion</title>
      <link>https://anhcodes.dev/blog/ai-avatar-sd-dreambooth/</link>
      <pubDate>Fri, 05 May 2023 18:06:47 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/ai-avatar-sd-dreambooth/</guid>
      <description>Table of Content Table of Content What is Stable Diffusion? What is DreamBooth? Options for Creating Your Own Images A 3-Step Process to Create Your Own AI Avatar for Free Step 1: Train Your Own Model with DreamBooth in Google Colabs Step 2: Download and Import the Model into Stable Diffusion WebUI Step 3: Use text2image Option to Generate Your Images Challenges and tips What is Stable Diffusion? Stable Diffusion is a deep learning model that can generate detailed images based on text descriptions.</description>
    </item>
    
    <item>
      <title>Debug long running Spark job</title>
      <link>https://anhcodes.dev/blog/mitigate-skew-spark/</link>
      <pubDate>Tue, 11 Apr 2023 23:20:57 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/mitigate-skew-spark/</guid>
      <description>You Spark job is running for a long time, what to do? Generally, long-running Spark jobs can be due to various factors. We like to call them the 5S - Spill, Skew, Shuffle, Storage, and Serialization. So, how do we identify the main culprit?
ðŸ”Ž Look for Skew: Are some of the tasks taking longer than others? Do you have a join operation?
ðŸ”Ž Look for Spill: Any out-of-memory errors? Do the executors have enough memory to finish their tasks?</description>
    </item>
    
    <item>
      <title>How to Scale and Tune Spark Effectively</title>
      <link>https://anhcodes.dev/blog/tune-spark/</link>
      <pubDate>Tue, 11 Apr 2023 23:20:57 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/tune-spark/</guid>
      <description>Spark is a distributed big data processing engine that uses the resilient distributed dataset (RDD) data structure with data abstractions such as DataFrames and Datasets. It provides API in different programming languages such as Scala, Python, and Java. One of the key benefits of Spark is that it decouples compute and storage, meaning it can be used to read from different data sources on-prem and in the cloud. Spark has four main APIs: Spark SQL, Spark MLlib, Spark Structured Streaming, and GraphX.</description>
    </item>
    
    <item>
      <title>Navigate Databricks FileSystem</title>
      <link>https://anhcodes.dev/blog/dbfs/</link>
      <pubDate>Tue, 11 Apr 2023 22:13:33 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/dbfs/</guid>
      <description> View Fullscreen View on Github </description>
    </item>
    
    <item>
      <title>The beauty of a data lakehouse</title>
      <link>https://anhcodes.dev/blog/data-lakehouse/</link>
      <pubDate>Tue, 11 Apr 2023 16:26:45 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/data-lakehouse/</guid>
      <description>Choosing Enterprise Data Solution is a key challenge for modern businesses. With the explosion of data in recent years, organizations need to be able to store, manage, and analyze vast amounts of information to gain insights and make informed decisions. Data lakes, data warehouses, and data lakehouses are three popular solutions for managing data. However, Data Lakehouse has recently become a trend in distributed data management system
The battle: Data Warehouse vs Data Lake vs Data Lakehouse A data warehouse is a centralized repository that stores structured, processed data from a variety of sources.</description>
    </item>
    
    <item>
      <title>Deploy Debezium and Kafka on AKS using Strimzi Operator</title>
      <link>https://anhcodes.dev/blog/deploy-debezium-aks/</link>
      <pubDate>Sat, 07 Jan 2023 00:19:27 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/deploy-debezium-aks/</guid>
      <description>This tutorial follows Debezium official documentation Deploying Debezium on Kubernetes, but modified for Azure Kubernetes Service and Azure Container Registry.
Table of Content Table of Content 1. Prerequisites Azure CLI Azure Kubernetes Cluster Set up kubectl in local Interact with your AKS cluster in your terminal 2. Deploy strimzi operator 3. Create secrets and roles 4. Deploy kafka cluster 5. Deploy the database (mysql) 6. Deploy Kafka Connect Cluster Step 1: Create a secret for your container registry in the same k8s namespace Step 2: Modify the KafkaConnect Manifest yaml to build and push image to Container Registry.</description>
    </item>
    
    <item>
      <title>How to recover lost files after a git reset --hard</title>
      <link>https://anhcodes.dev/blog/recover-lost-files-git-reset-hard/</link>
      <pubDate>Tue, 27 Dec 2022 11:30:20 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/recover-lost-files-git-reset-hard/</guid>
      <description>While working on a recent project, I accidentally committed some files. Instead of using git reset --soft &amp;lt;prev-commit-id&amp;gt; to unstage them, I used git reset --hard HEAD and all of my new changes gone with the wind. After panicking for a few minutes, I determined to learn how git reset works and how I can revert the damages.
1. What is git reset (hard vs soft) git reset --hard resets the current branch tip, and also deletes any changes in the working directory and staging area (although files under git stash will not be affected).</description>
    </item>
    
    <item>
      <title>Query Performance Tuning in Dedicated SQL Pool (Azure Synapse Analytics)</title>
      <link>https://anhcodes.dev/blog/query-performance/</link>
      <pubDate>Thu, 15 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/query-performance/</guid>
      <description>1. Best practices when Creating Tables 2. Identify slow-running QID and analyze compilation 3. Analyze the distributed query plan 4. Analyze a specific query plan 5. Analyze impacts of concurrent workload 1. Best practices when Creating Tables When creating table in Dedicated SQL Pool, choose the correct Distribution Column and Index for best query performance. Follow Best Practices in creating tables in Azure Synapse Analytics
Remember to create and Update Stats on your new tables Table statistics for dedicated SQL pool in Azure Synapse Analytics</description>
    </item>
    
    <item>
      <title>Best Practices in creating tables in Azure Synapse Analytics</title>
      <link>https://anhcodes.dev/blog/create-table-azure-synapse-analytics/</link>
      <pubDate>Tue, 15 Nov 2022 23:24:30 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/create-table-azure-synapse-analytics/</guid>
      <description>As Dedicated SQL pool uses a scaled-out node based architecture, when creating tables in Dedicated SQL Pool, remember to specify the distribution (sharding strategy) and index for your tables.
Dedicated SQL Pool Architecture Choosing Distribution: The data is sharded into distributions to optimize the performance of the system. You can choose which sharding pattern to use to distribute the data when you define the table. These sharding patterns are supported:</description>
    </item>
    
    <item>
      <title>Azure Synapse Analytics - Data Lakehouse on Azure</title>
      <link>https://anhcodes.dev/blog/synapse/</link>
      <pubDate>Tue, 15 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/synapse/</guid>
      <description>Table of Contents Table of Contents What is Azure Synapse Analytics? What is Dedicated SQL Pool? What is Serverless SQL Pool? Dedicated vs Serverless SQL Pool Comparison Azure Synapse Analytics, AWS Redshift, Google Big Query Comparison What is Azure Synapse Analytics? Azure Synapse Analytics is an integrated data platform that brings together SQL technologies used in enterprise data warehousing such as Dedicated SQL Pool and Serverless SQL Pool, Synapse Spark Pool used for big data, Data Explorer for log and time series analytics, Synapse Pipelines for data integration and ETL/ELT, and deep integration with other Azure services such as Power BI, CosmosDB, and AzureML.</description>
    </item>
    
  </channel>
</rss>
