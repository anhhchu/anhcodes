<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data, Coding &amp; More on anhcodes</title>
    <link>https://anhcodes.dev/blog/</link>
    <description>Recent content in Data, Coding &amp; More on anhcodes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 27 May 2023 21:48:00 +0000</lastBuildDate><atom:link href="https://anhcodes.dev/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Spark working internals, and why should you care?</title>
      <link>https://anhcodes.dev/blog/tune-spark/</link>
      <pubDate>Sat, 27 May 2023 21:48:00 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/tune-spark/</guid>
      <description>Spark Architecture Spark Cluster Components Spark Session Spark APIs Computation in Spark Spark Catalyst Optimizer Adaptive Query Execution Shuffle, Partitioning and Caching in Spark Partitioning Shuffle Cache in Spark Most Big Data developers and Data Engineers start learning Spark by writing SparkSQL codes to perform ETL on DataFrame (I know I did). I also wrote a post about SparkSQL Programming. However, we quickly learn that thereâ€™s more knowlege required to go from processing a few GBs of data to dealing with TBs and PBs of data, which is a challenge for big enterprises.</description>
    </item>
    
    <item>
      <title>Spark SQL Programming Primer</title>
      <link>https://anhcodes.dev/blog/spark-sql-programming/</link>
      <pubDate>Tue, 23 May 2023 17:09:34 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/spark-sql-programming/</guid>
      <description>TL,DR - SparkSQL is a huge component of Spark Programming. This post introduces programming in SparkSQL through Spark DataFrame API. It&amp;rsquo;s important to be aware of Spark SQL built-in functions to be a more efficient Spark programmer
What is SparkSQL DataFrame API in SparkSQL Read and write data with Spark DataFrame Columns in DF Rows in DF Data Operations in Spark DataFrame SparkSQL Built-in Functions 1. Aggregation functions 2. Datetime functions 3.</description>
    </item>
    
    <item>
      <title>Debug long running Spark job</title>
      <link>https://anhcodes.dev/blog/debug-spark/</link>
      <pubDate>Mon, 22 May 2023 17:09:41 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/debug-spark/</guid>
      <description>You Spark job is running for a long time, what to do? Generally, long-running Spark jobs can be due to various factors. We like to call them the 5S - Spill, Skew, Shuffle, Storage, and Serialization. So, how do we identify the main culprit?
ðŸ”Ž Look for Skew: Are some of the tasks taking longer than others? Do you have a join operation?
ðŸ”Ž Look for Spill: Any out-of-memory errors? Do the executors have enough memory to finish their tasks?</description>
    </item>
    
    <item>
      <title>Navigate Databricks FileSystem</title>
      <link>https://anhcodes.dev/blog/dbfs/</link>
      <pubDate>Tue, 11 Apr 2023 22:13:33 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/dbfs/</guid>
      <description> View Fullscreen View on Github </description>
    </item>
    
    <item>
      <title>The beauty of a data lakehouse</title>
      <link>https://anhcodes.dev/blog/data-lakehouse/</link>
      <pubDate>Tue, 11 Apr 2023 16:26:45 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/data-lakehouse/</guid>
      <description>Choosing Enterprise Data Solution is a key challenge for modern businesses. With the explosion of data in recent years, organizations need to be able to store, manage, and analyze vast amounts of information to gain insights and make informed decisions. Data lakes, data warehouses, and data lakehouses are three popular solutions for managing data. However, Data Lakehouse has recently become a trend in distributed data management system
The battle: Data Warehouse vs Data Lake vs Data Lakehouse A data warehouse is a centralized repository that stores structured, processed data from a variety of sources.</description>
    </item>
    
    <item>
      <title>Deploy Debezium and Kafka on AKS using Strimzi Operator</title>
      <link>https://anhcodes.dev/blog/deploy-debezium-aks/</link>
      <pubDate>Sat, 07 Jan 2023 00:19:27 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/deploy-debezium-aks/</guid>
      <description>This tutorial follows Debezium official documentation Deploying Debezium on Kubernetes, but modified for Azure Kubernetes Service and Azure Container Registry.
Table of Content Table of Content 1. Prerequisites Azure CLI Azure Kubernetes Cluster Set up kubectl in local Interact with your AKS cluster in your terminal 2. Deploy strimzi operator 3. Create secrets and roles 4. Deploy kafka cluster 5. Deploy the database (mysql) 6. Deploy Kafka Connect Cluster Step 1: Create a secret for your container registry in the same k8s namespace Step 2: Modify the KafkaConnect Manifest yaml to build and push image to Container Registry.</description>
    </item>
    
    <item>
      <title>How to recover lost files after a git reset --hard</title>
      <link>https://anhcodes.dev/blog/recover-lost-files-git-reset-hard/</link>
      <pubDate>Tue, 27 Dec 2022 11:30:20 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/recover-lost-files-git-reset-hard/</guid>
      <description>While working on a recent project, I accidentally committed some files. Instead of using git reset --soft &amp;lt;prev-commit-id&amp;gt; to unstage them, I used git reset --hard HEAD and all of my new changes gone with the wind. After panicking for a few minutes, I determined to learn how git reset works and how I can revert the damages.
1. What is git reset (hard vs soft) git reset --hard resets the current branch tip, and also deletes any changes in the working directory and staging area (although files under git stash will not be affected).</description>
    </item>
    
    <item>
      <title>Query Performance Tuning in Dedicated SQL Pool (Azure Synapse Analytics)</title>
      <link>https://anhcodes.dev/blog/query-performance/</link>
      <pubDate>Thu, 15 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/query-performance/</guid>
      <description>1. Best practices when Creating Tables 2. Identify slow-running QID and analyze compilation 3. Analyze the distributed query plan 4. Analyze a specific query plan 5. Analyze impacts of concurrent workload 1. Best practices when Creating Tables When creating table in Dedicated SQL Pool, choose the correct Distribution Column and Index for best query performance. Follow Best Practices in creating tables in Azure Synapse Analytics
Remember to create and Update Stats on your new tables Table statistics for dedicated SQL pool in Azure Synapse Analytics</description>
    </item>
    
    <item>
      <title>Best Practices in creating tables in Azure Synapse Analytics</title>
      <link>https://anhcodes.dev/blog/create-table-azure-synapse-analytics/</link>
      <pubDate>Tue, 15 Nov 2022 23:24:30 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/create-table-azure-synapse-analytics/</guid>
      <description>As Dedicated SQL pool uses a scaled-out node based architecture, when creating tables in Dedicated SQL Pool, remember to specify the distribution (sharding strategy) and index for your tables.
Dedicated SQL Pool Architecture Choosing Distribution: The data is sharded into distributions to optimize the performance of the system. You can choose which sharding pattern to use to distribute the data when you define the table. These sharding patterns are supported:</description>
    </item>
    
    <item>
      <title>Azure Synapse Analytics - Data Lakehouse on Azure</title>
      <link>https://anhcodes.dev/blog/synapse/</link>
      <pubDate>Tue, 15 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://anhcodes.dev/blog/synapse/</guid>
      <description>Table of Contents Table of Contents What is Azure Synapse Analytics? What is Dedicated SQL Pool? What is Serverless SQL Pool? Dedicated vs Serverless SQL Pool Comparison Azure Synapse Analytics, AWS Redshift, Google Big Query Comparison What is Azure Synapse Analytics? Azure Synapse Analytics is an integrated data platform that brings together SQL technologies used in enterprise data warehousing such as Dedicated SQL Pool and Serverless SQL Pool, Synapse Spark Pool used for big data, Data Explorer for log and time series analytics, Synapse Pipelines for data integration and ETL/ELT, and deep integration with other Azure services such as Power BI, CosmosDB, and AzureML.</description>
    </item>
    
  </channel>
</rss>
